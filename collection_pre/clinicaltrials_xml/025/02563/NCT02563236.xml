<DOC>
	<DOC>NCT02563236</DOC>
	<brief_summary>During a space mission the crew has to perform a wide variety of tasks under different acceleration conditions. For handling of displays and control items during a mission, the astronaut's performance is strong depended on an intuitive usability. Currently investigators are exploring and developing different Augmented Reality interfaces for the International Standard Payload Rack (ISPR) Biolab that is installed in the International Space Station (ISS) module Columbus. Augmented reality (AR) is a live, direct or indirect, view of a physical, real-world environment whose elements are augmented by computer-generated sensory input such as sound, video, graphics or GPS data. Using AR technologies provides user-oriented support for working procedures in development, production, and operating of complex technical products and systems. It is conceivable that in future manned missions such interfaces will be applied to space operations, where the astronaut will handle virtual information that enriches the physical reality. To improve the support for the operational ground team and the space crew by performing service and maintenance tasks at the Columbus space laboratory Biolab, investigators explore innovative tridimensional (3D) interaction techniques that allow an intuitive way to interact with the virtual content. The developed AR interfaces for the ISPR Biolab ought to offer support while handling standardize service and maintenance procedures. This research is primarily focused on supporting the ground team during their work at the engineering model of Biolab that is located in Cologne at the Institute of Aerospace Medicine. Applying these interfaces subsequently to space operations requires previous exploration regarding the influence of different acceleration conditions that ought to be considered at the investigators' current stage of designing and development. Thereby one important aspect is focused on the correct placement of virtual user interfaces while interacting with it. To explore human adaption of handling and controlling virtual AR interfaces, this experiment denotes a usability study that will supply findings about human mental workload and sensorimotor coordination while performing the experimentation task under different accelerations of gravity. The proposed experiment will supply essential information about understanding the adequate quality characteristics concerning placement of virtual interfaces in physical reality and identify disturbing factors while applying in hyper-g and micro-g conditions.</brief_summary>
	<brief_title>Evaluation of 3D Selection Tasks in Parabolic Flight Conditions: Pointing Task in Augmented Reality User Interfaces</brief_title>
	<detailed_description>Investigations description --------------------------------- Augmented Reality 2 different Head-Mounted-Displays (ARVision3D from Trivisio; dataGlass/2A from Shimadzu), controlled by 2 PC will be used. The first HMD is a monocular optical see-through (OST) HMD: it is equipped with a semi-transparent LCD display for one eye. The user can directly see the physical world without limitations regarding the peripheral field of view. The second HMD is a binocular video see-through (VST) HMD: it is equipped with two LCD displays and a stereo camera system that records the physical environment and replays the video onto the displays in real-time. Experimental protocol ---------------------------- Before flight subjects will be familiarized with the setup and the protocol. For each flight day, 2 subjects will be studied one for each AR device. Halfway during the flight, the 2 subjects will swap places. The procedure will be the following on all 3 days. The experiment day will start at 7.30 a.m. with the test subjects equipped with heart rate recording device. After take-off and after work will be permitted, the 2 subjects will go to the experimental area where they will be seated. They will be equipped with one of the HMD (optical- or video-see through HM). During a parabola the subjects perform the experimentation task: symbolic input of five letters onto virtual keyboard depending on the experimental task during a parabola. To point towards the virtual keyboard the subject wears a thimble on his forefinger. The body-alignment scenario requires an additional panel on subject's non-dominant hand. During a parabola two subjects perform the tasks - one is using HMD type 1 in hyper-g and the other subject is using HMD type 2 in micro-g. During the 8 minute rest period between parabolas 15 and 16, the 2 test subjects will switch places. Switching place will be a straightforward process as each member of our team has expertise in manning the test equipment.</detailed_description>
	<criteria>Healthy volunteers (men or women) Aged from 21 to 55 Affiliated to a Social Security system and, for nonFrench resident, holding a European Health Insurance Card (EHIC) Who accepted to take part in the study Who has already experience in handling specific AR interfaces while wearing an HMD Who have given their written stated consent Who has passed a medical examination similar to a standard aviation medical examination for private pilot aptitude. There will be no additional test performed for subject selection. Person who took part in a previous biomedical research protocol, of which exclusion period is not terminated Pregnant women</criteria>
	<gender>All</gender>
	<minimum_age>21 Years</minimum_age>
	<maximum_age>55 Years</maximum_age>
	<verification_date>September 2015</verification_date>
</DOC>